{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "weakclassifiers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4IFFNwIF0vT"
      },
      "source": [
        "# Practical session ML: Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY8O7TWoF0vk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn import datasets, neighbors, metrics, tree\n",
        "\n",
        "def class_accs(predicted_labels, test_labels):\n",
        "    indices0 = []\n",
        "    indices1 = []\n",
        "    for i, label in enumerate(test_labels):\n",
        "        if label == 0:\n",
        "            indices0.append(i)\n",
        "        else:\n",
        "            indices1.append(i)\n",
        "    accuracy0 = metrics.accuracy_score([0] * len(indices0), predicted_labels[indices0])\n",
        "    accuracy1 = metrics.accuracy_score([1] * len(indices1), predicted_labels[indices1])\n",
        "    return accuracy0, accuracy1\n",
        "\n",
        "def print_metrics(predicted_labels, test_labels):\n",
        "    f1 = metrics.f1_score(test_labels, predicted_labels)\n",
        "    accuracy = metrics.accuracy_score(test_labels, predicted_labels)\n",
        "    \n",
        "    accuracy0, accuracy1 = class_accs(predicted_labels, test_labels)\n",
        "\n",
        "    print('\\tF1 = {}'.format(f1))\n",
        "    print('\\tAccuracy = {}'.format(accuracy))\n",
        "    print('\\t\\tclass 0: {}'.format(accuracy0))\n",
        "    print('\\t\\tclass 1: {}'.format(accuracy1))\n",
        "    print()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uBS5NX1F0v0"
      },
      "source": [
        "Load the Wisconsin breast cancer data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcRvRke3F0v1",
        "outputId": "5dcdfa93-5b19-486d-d40e-0a41b191ec41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load the Wisconsin breast cancer data set\n",
        "wisconsin = datasets.load_breast_cancer()\n",
        "\n",
        "# explore the data set\n",
        "print('Data set contains {} instances with {} features.'.format(wisconsin['data'].shape[0], wisconsin['data'].shape[1]))\n",
        "print('The different classes are {}.'.format(wisconsin['target_names']))\n",
        "\n",
        "count0 = len([x for x in wisconsin['target'] if x == 0])\n",
        "count1 = len([x for x in wisconsin['target'] if x == 1])\n",
        "print('{} contains {} samples, {} contains {}.'.format(wisconsin['target_names'][0], count0, wisconsin['target_names'][1], count1))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data set contains 569 instances with 30 features.\n",
            "The different classes are ['malignant' 'benign'].\n",
            "malignant contains 212 samples, benign contains 357.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj2nbG31F0v8"
      },
      "source": [
        "As an example, we will train a decision tree classifier on this data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lym0uFrF0v9",
        "outputId": "473a0d0c-54a0-4749-df1c-8a2515fa51bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dt = tree.DecisionTreeClassifier()\n",
        "dt.fit(wisconsin['data'], wisconsin['target'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGxyCvEtF0wC"
      },
      "source": [
        "## Illustration\n",
        "\n",
        "Divide the dataset in five folds for cross-validation. Use stratified CV, meaning that the original class distribution is respected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD-R8YPwF0wC"
      },
      "source": [
        "# split into classes\n",
        "malignant = []\n",
        "benign = []\n",
        "for x, y in zip(wisconsin['data'], wisconsin['target']):\n",
        "    if y == 0:\n",
        "        malignant.append(x)\n",
        "    else:\n",
        "        benign.append(x)\n",
        "\n",
        "random.seed(1)\n",
        "random.shuffle(malignant)\n",
        "random.shuffle(benign)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RqUCFIBF0wG",
        "outputId": "08730161-c412-4660-a955-9442e4a33a6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# try n-NN classification with k-fold CV\n",
        "folds = 5\n",
        "k = 3\n",
        "bal_accs = []\n",
        "for i in range(folds):\n",
        "    start_malignant = i * len(malignant) // folds\n",
        "    end_malignant = (i+1) * len(malignant) // folds\n",
        "    \n",
        "    start_benign = i * len(benign) // folds\n",
        "    end_benign = (i+1) * len(benign) // folds\n",
        "    \n",
        "    training_malignant = malignant[:start_malignant] + malignant[end_malignant:]\n",
        "    training_benign = benign[:start_benign] + benign[end_benign:]\n",
        "    \n",
        "    training_set = training_malignant + training_benign\n",
        "    training_labels = [0 for _ in training_malignant] + [1 for _ in training_benign]\n",
        "    \n",
        "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(training_set, training_labels)\n",
        "    \n",
        "    test_malignant = malignant[start_malignant:end_malignant]\n",
        "    test_benign = benign[start_benign:end_benign]\n",
        "    test_set = test_malignant + test_benign\n",
        "    test_labels = [0 for _ in test_malignant] + [1 for _ in test_benign]\n",
        "    predicted_labels = knn.predict(test_set)\n",
        "\n",
        "    acc0, acc1 = class_accs(predicted_labels, test_labels)\n",
        "    bal_acc = (acc0 + acc1) / 2.\n",
        "    bal_accs.append(bal_acc)\n",
        "print('Balanced accuracy: {}'.format(np.mean(bal_accs)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Balanced accuracy: 0.9129005297937496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvmq1OhBF0wJ"
      },
      "source": [
        "For SVM and Decision Trees we can use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o18iOTgnF0wK"
      },
      "source": [
        "# create a decision tree\n",
        "dt = tree.DecisionTreeClassifier()\n",
        "# dt.fit(training_set, training_labels)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qik-9Ek3F0wO"
      },
      "source": [
        "## Exercise 1\n",
        "\n",
        "Compare the performance of kNN and Decision Trees on the Wisconsin data set. Vary the internal parameters (number of nearest neighbors, impurity measure,  etc.). Consult the [API documentation](http://scikit-learn.org/stable/modules/classes.html) for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtGo5maSF0wP"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}